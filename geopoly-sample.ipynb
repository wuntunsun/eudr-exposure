{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import rasterio as rio\n",
    "from rasterio import features\n",
    "from rasterio.windows import Window\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "import itertools as it\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.plot import show\n",
    "from rasterio.warp import transform\n",
    "\n",
    "xs = np.array([3327493.433, 16177493.43])\n",
    "ys = np.array([7389201.61, -580798.392])\n",
    "\n",
    "lossyear = 'data/Hansen_GFC-2022-v1.10_lossyear_50N_000E.tif'\n",
    "datamask = 'data/Hansen_GFC-2022-v1.10_datamask_50N_000E.tif'\n",
    "foo = 'data/TCL_DD_2022_20230407.tif'\n",
    "\n",
    "src = rio.open(foo)\n",
    "band = src.read(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = band != 12\n",
    "shapes = features.shapes(band, mask=mask, transform=src.transform)\n",
    "pp.pprint(next(shapes)) # first element\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "({'coordinates': [[(1.4645000000000001, 50.0),\n",
    "                   (1.4645000000000001, 49.99975),\n",
    "                   (1.46525, 49.99975),\n",
    "                   (1.46525, 49.9995),\n",
    "                   (1.4655, 49.9995),\n",
    "                   (1.4655, 50.0),\n",
    "                   (1.4645000000000001, 50.0)]],\n",
    "  'type': 'Polygon'},\n",
    " 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterio.features.dataset_features # works on raster value rather than mask...\n",
    "\n",
    "with rio.open('data/TCL_DD_2022_20230407.tif') as src:\n",
    "    # TODO: check src.count for number of bands...\n",
    "    print(src.meta)\n",
    "    band = src.read(1)\n",
    "    mask = band == 1\n",
    "    # Object holding a feature collection that implements the __geo_interface__\n",
    "    # TODO: result should be in EPSG 4326 i.e. GPS\n",
    "    results = (\n",
    "        {'properties': {'deforestation': v}, 'geometry': s}\n",
    "        for i, (s, v) in enumerate(\n",
    "            features.shapes(band, mask=mask)\n",
    "            )\n",
    "        )\n",
    "    geoms=list(results)\n",
    "    gdf = gpd.GeoDataFrame.from_features(geoms)\n",
    "    \n",
    "gdf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "geometry\tdeforestation\n",
    "0\tPOLYGON ((2870.000 104.000, 2870.000 105.000, ...\t4.0\n",
    "1\tPOLYGON ((2777.000 110.000, 2777.000 111.000, ...\t4.0\n",
    "2\tPOLYGON ((2778.000 111.000, 2778.000 112.000, ...\t4.0\n",
    "3\tPOLYGON ((2730.000 113.000, 2730.000 114.000, ...\t4.0\n",
    "4\tPOLYGON ((2737.000 113.000, 2737.000 114.000, ...\t4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterio.features.dataset_features # works on raster value rather than mask...\n",
    "\n",
    "with rio.open('data/Hansen_GFC-2022-v1.10_lossyear_20S_060W.tif') as src:\n",
    "    # TODO: check src.count for number of bands...\n",
    "    print(src.meta)\n",
    "    band = src.read(1, window=Window(2100, 2000, 6000, 6000))\n",
    "    #band = src.read(1)\n",
    "    print(band.shape)\n",
    "    rdf = gpd.GeoDataFrame()\n",
    "    mask = band != 0\n",
    "    # Object holding a feature collection that implements the __geo_interface__\n",
    "    # TODO: result should be in EPSG 4326 i.e. GPS\n",
    "    results = (\n",
    "        {'properties': {'lossyear': v}, 'geometry': s}\n",
    "        for i, (s, v) in enumerate(\n",
    "            # connectivity, 4 on edges, 8 on edges and corners...\n",
    "            features.shapes(band, mask=mask, connectivity=8)\n",
    "            )\n",
    "        )\n",
    "    geoms=list(results)\n",
    "    gdf = gpd.GeoDataFrame.from_features(geoms)\n",
    "    rdf = gpd.GeoDataFrame( pd.concat( [rdf, gdf], ignore_index=True), crs=gdf.crs)\n",
    "\n",
    "print(f'Chosen Window results in GeoDataFrame of .shape: {rdf.shape}')\n",
    "rdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.plot(column='lossyear', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sjoin does not modify the geometry...\n",
    "intersects = rdf.sjoin(rdf, how=\"left\", predicate=\"intersects\")\n",
    "intersects.shape, intersects.index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersects.reset_index(inplace=True)\n",
    "intersects.rename(columns={'index': 'index_left'}, inplace=True)\n",
    "intersects.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota bene: Robert Norris - this removes the self-intersection aggregates index_right, but\n",
    "# also aggregates all other values into lists... it also spends far too much time in unary_union\n",
    "# on geometry, the result of which we do not need.\n",
    "#temp = intersects.dissolve(\"index_left\", aggfunc=lambda x: x.tolist(),)\n",
    "\n",
    "# Group by 'index_left', truncate intersects, then aggregate on 'index_right' only...\n",
    "groups = intersects.groupby('index_left')\n",
    "temp = intersects[intersects['index_left'] == intersects['index_right']].set_index('index_left')\n",
    "temp['indices'] = groups['index_right'].aggregate(lambda x: x.tolist())\n",
    "temp['indices'] = temp['indices'].apply(lambda x: np.sort(x))\n",
    "\n",
    "temp.index.name = None\n",
    "temp['lossyear'] = temp['lossyear_left'].astype(\"int\") + 2000\n",
    "temp.drop(['index_right', 'lossyear_left', 'lossyear_right'], axis=1, inplace=True)\n",
    "\n",
    "temp.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group_id = 'group'\n",
    "\n",
    "# See https://stackoverflow.com/questions/73566774/group-by-and-combine-intersecting-overlapping-geometries-in-geopandas\n",
    "# This is not quite right... 5 should be part of the same group as 2, but since it was\n",
    "# not previously encountered, a new group_id is taken that...\n",
    "# we would need to take any of 'indices' that have previously been encountered...\n",
    "\n",
    "'''\n",
    "                 indices group\n",
    "0                    [0]     0\n",
    "1                    [1]     1\n",
    "2                 [2, 3]     2\n",
    "3           [2, 3, 4, 6]     2\n",
    "4        [3, 4, 6, 7, 9]     2\n",
    "5                 [5, 6]  None\n",
    "6  [3, 4, 5, 6, 7, 8, 9]     2\n",
    "                 indices group\n",
    "0                    [0]     0\n",
    "1                    [1]     1\n",
    "2                 [2, 3]     2\n",
    "3           [2, 3, 4, 6]     2\n",
    "4        [3, 4, 6, 7, 9]     2\n",
    "5                 [5, 6]     5\n",
    "6  [3, 4, 5, 6, 7, 8, 9]     2\n",
    "                 indices group\n",
    "0                    [0]     0\n",
    "1                    [1]     1\n",
    "2                 [2, 3]     2\n",
    "3           [2, 3, 4, 6]     2\n",
    "4        [3, 4, 6, 7, 9]     2\n",
    "5                 [5, 6]     5\n",
    "6  [3, 4, 5, 6, 7, 8, 9]     5                 \n",
    "'''\n",
    "\n",
    "index_generator = range(len(temp))\n",
    "start = time.time()\n",
    "counter = it.count()\n",
    "\n",
    "indices = temp['indices'].to_numpy()\n",
    "groups = pd.Series([None] * len(temp))\n",
    "\n",
    "for i, array in tqdm(zip(counter, indices), total=len(temp)):\n",
    "    first_valid_index = groups.loc[array].first_valid_index()\n",
    "    id = i if first_valid_index == None else groups.loc[first_valid_index]\n",
    "    groups.loc[array] = id\n",
    "end = time.time()\n",
    "print(f'Loop over {len(temp)} took {end-start}s')\n",
    "\n",
    "temp[group_id] = groups.copy()\n",
    "\n",
    "# want to dissolve based on lossyear to generate any MULTIPOLYGON from disjoint geometry from same lossyear...\n",
    "temp2 = temp.dissolve(\n",
    "    [group_id, 'lossyear']\n",
    ")\n",
    "#temp.reset_index(inplace=True)\n",
    "print(f'intersects.dissolve on group_id, lossyear in GeoDataFrame of .shape: {temp2.shape}')\n",
    "\n",
    "temp2.head(30)\n",
    "#temp['indices']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = temp2.index.get_level_values(0).unique()\n",
    "lossyears = range(2001, 2023)\n",
    "\n",
    "#temp3 = temp2.set_index([group_id, 'lossyear'])\n",
    "index = pd.MultiIndex.from_tuples(tuples=it.product(group_ids, lossyears), names=(group_id, 'lossyear'))\n",
    "temp3 = temp2.reindex(index)\n",
    "\n",
    "temp3.head(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be aware of chained indexing as it may call __get_item__ before __set_item__ which will fail on Nan/None etc.\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "\n",
    "#temp.index.names, temp.index.levels, temp.index.codes\n",
    "#temp.isna() # shows only rows where at least one column value is set...\n",
    "#temp.fillna(0)\n",
    "#temp.loc[(1, 2018), 'geometry'] = None\n",
    "#temp.loc[(1, 2017), 'index_right'] = 666\n",
    "#temp.loc[:,].isnull().sum()\n",
    "#temp.loc[temp.loc[:,].isna(), 'geometry']\n",
    "#temp.geometry.fillna()\n",
    "#temp.head()\n",
    "#temp.loc[1,2019].geometry = None #shapely.geometry.Polygon([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3.loc[temp3['geometry'].isna(), 'geometry'] = Polygon([])\n",
    "temp3['area'] = temp3.geometry.area\n",
    "temp3['cum_area'] = temp3.groupby(group_id).area.cumsum()\n",
    "\n",
    "for i in tqdm(group_ids.to_numpy()):\n",
    "    temp3.loc[i, 'cum_geometry'] = list(it.accumulate(temp3.loc[i, 'geometry'], func=lambda x,y: x.union(y)))\n",
    "\n",
    "temp3.reset_index(inplace=True)\n",
    "\n",
    "temp3.drop(temp3[temp3.area == 0].index, inplace=True)\n",
    "\n",
    "print(f'...and a final GeoDataFrame of .shape: {temp3.shape}')\n",
    "\n",
    "temp3.to_csv('data/geoply-sample.csv')\n",
    "temp3.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
