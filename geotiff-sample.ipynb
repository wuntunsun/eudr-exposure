{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "from rasterio.warp import transform\n",
    "from rasterio.transform import (xy, rowcol)\n",
    "from rasterio.windows import Window\n",
    "import itertools as it\n",
    "import rioxarray as rx\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([3327493.433, 16177493.43])\n",
    "ys = np.array([7389201.61, -580798.392])\n",
    "\n",
    "with rio.open(\"data/TCL_DD_2022_20230407.tif\") as src:\n",
    "\n",
    "    pt = src.xy(0, 0) # latitude is N/S AKA y, \n",
    "\n",
    "    print(f'Number of bands: {src.count}')\n",
    "    print(f'Image resolution: ({src.height}, {src.width})')\n",
    "    print(f'Coordinate Reference System: ({src.crs}')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    extent = [src.bounds[0], src.bounds[2], src.bounds[1], src.bounds[3]]\n",
    "    ax = show(src, extent=extent, ax=ax, cmap=\"pink\")\n",
    "\n",
    "    # https://epsg.io/4326\n",
    "    # WGS 84 -- WGS84 - World Geodetic System 1984, used in GPS\n",
    "\n",
    "    # 18.18517 55.56466\n",
    "    # 29.766234, 69.421527 (latitude, longitude) pakistan\n",
    "    # -15.28575, -55.94627 (latitude, longitude) brazil\n",
    "    lat = -15.28575\n",
    "    long = -55.94627\n",
    "\n",
    "    to_crs = src.crs\n",
    "    from_crs = rio.crs.CRS.from_epsg(4326)\n",
    "    x, y = transform(from_crs, to_crs, [long], [lat])\n",
    "\n",
    "    # expect 1 - 5... but mention is made of Zero or Minor Loss\n",
    "    # 1. CommodityDriven.Deforestation\n",
    "    # 2. Shifting.Agriculture\n",
    "    # 3. TreeFarm.ForestryOther\n",
    "    # 4. Wildfire\n",
    "    # 5. Urban\n",
    "\n",
    "    for val in src.sample([(x, y)]): \n",
    "        print(val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.set_options(display_expand_attrs=False, display_expand_data=False)\n",
    "ds = xr.tutorial.load_dataset(\"air_temperature\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)\n",
    "ds.air.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterio.features.dataset_features # works on raster value rather than mask...\n",
    "# data.attrs[\"units\"] = \"metres/sec\"\n",
    "# rioxarray combines xarray and rasterio similar to how geopandas combines functionality from pandas and fiona\n",
    "# and if you want to connect between geopandas and xarray, you can use geocube...\n",
    "\n",
    "lat = -22.00027\n",
    "long = -58.99658\n",
    "\n",
    "# we can convert to and from pixel data with xy and rowcol respectively\n",
    "# nearest neighbout in raster space would be the shortest distance in pixel space\n",
    "# for certain values\n",
    "# convert query from GPS to rowcol\n",
    "# mask values not of interest... find rowcol of closest\n",
    "# convert from rowcol to GPS\n",
    "\n",
    "# shapely.ops.nearest_points(geom1, geom2)\n",
    "# but we use rowcol values that can then be converted back to xy AKA GPS\n",
    "# this way we would have 40000 x 40000 Point rather than pixel values\n",
    "# distance calculation on projection may be distorted...\n",
    "# use ‘haversine’ distance\n",
    "\n",
    "\n",
    "\n",
    "with rx.open_rasterio('data/Hansen_GFC-2022-v1.10_lossyear_20S_060W.tif').squeeze() as xda:\n",
    "    \n",
    "    #print(xda)\n",
    "    \n",
    "    #xda.rio.write_crs(3347, inplace=True)\n",
    "    #print(xda.spatial_ref)\n",
    "\n",
    "    #xda.rio.set_spatial_dims(\"lon\", \"lat\", inplace=True)\n",
    "\n",
    "    # band is lossyear\n",
    "    # x is long\n",
    "    # y is lat\n",
    "\n",
    "    to_crs = xda.rio.crs\n",
    "    from_crs = rio.crs.CRS.from_epsg(4326)\n",
    "    x, y = transform(from_crs, to_crs, [long], [lat])\n",
    "\n",
    "    # If you use \"projected coordinate system\", no problem. The distance that \n",
    "    # you get is the distance on the map (not on the spherical earth). When \n",
    "    # using \"geographic coordinate system - GCS\", the distance that you get \n",
    "    # will be the shortest distance in 3D space.\n",
    "\n",
    "    # This uses the ‘haversine’ formula to calculate the great-circle distance\n",
    "    # between two points – that is, the shortest distance over the earth’s surface\n",
    "    #  – giving an ‘as-the-crow-flies’ distance between the points (ignoring any \n",
    "    # hills they fly over, of course!).\n",
    "\n",
    "    #xarray_distance.data = np.sqrt((lat - spec_lat)[:,None]**2 + ((lon - spec_lon)**2)\n",
    "    \n",
    "    # get value from grid\n",
    "    value = xda.sel(x=x[0], y=y[0], method=\"nearest\")\n",
    "    # ... is unspecified or infinite number of arguments!\n",
    "    print(value)\n",
    "\n",
    "    # An empty (tuple) index is a full scalar index into a zero dimensional array. x[()] returns a scalar\n",
    "    # if x is zero dimensional and a view otherwise. On the other hand x[...] always returns a view.\n",
    "\n",
    "    # When an ellipsis (...) is present but has no size (i.e. replaces zero :) the \n",
    "    # result will still always be an array. A view if no advanced index is present, otherwise a copy.\n",
    "\n",
    "    #value.values[()]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to grab treecover2000 per asset/location, and pixels per lossyear\n",
    "# The result is a simple DataFrame as we do not use shapely geometry...\n",
    "\n",
    "lat = -22.00027\n",
    "long = -58.99658\n",
    "offset = 16 # 16 * 2 + 1 == 33, odd number allows for single pixel centre, sides are close to 1km\n",
    "\n",
    "# The term \"kernel\" in the context of convolutional neural networks (CNNs) comes from image processing \n",
    "# and mathematics, specifically from the field of signal processing. In image processing, a kernel is a \n",
    "# small matrix used for blurring, sharpening, edge detection, or other image processing operations.\n",
    "# kernel -- a small matrix of weights --\n",
    "\n",
    "# data/Hansen_GFC-2022-v1.10_treecover2000_10S_050W.tif \n",
    "# data/Hansen_GFC-2022-v1.10_treecover2000_10S_060W.tif \n",
    "# data/Hansen_GFC-2022-v1.10_treecover2000_20S_050W.tif \n",
    "# data/Hansen_GFC-2022-v1.10_treecover2000_20S_060W.tif\n",
    "\n",
    "# data/Hansen_GFC-2022-v1.10_lossyear_10S_050W.tif \n",
    "# data/Hansen_GFC-2022-v1.10_lossyear_10S_060W.tif \n",
    "# data/Hansen_GFC-2022-v1.10_lossyear_20S_050W.tif \n",
    "# data/Hansen_GFC-2022-v1.10_lossyear_20S_060W.tif\n",
    "\n",
    "assets = pd.read_csv('data/assets_for_deforestation.csv', sep='\\t')\n",
    "assets.shape, assets.uid_gem.unique().size, assets.head()\n",
    "# TODO: should not be needed...\n",
    "assets.drop_duplicates('uid_gem', inplace=True)\n",
    "assets = assets.set_index('uid_gem')\n",
    "assets.shape, assets.index.unique().size, assets.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "uid_gems = assets.index.unique()\n",
    "lossyears = range(2001, 2023)\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(tuples=it.product(uid_gems, lossyears), names=('uid_gem', 'lossyear'))\n",
    "xda = rx.open_rasterio('data/Hansen_GFC-2022-v1.10_lossyear_20S_060W.tif').squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(xda)\n",
    "\n",
    "to_crs = xda.rio.crs\n",
    "from_crs = rio.crs.CRS.from_epsg(4326)\n",
    "xs, ys = transform(from_crs, to_crs, assets.longitude, assets.latitude)\n",
    "#print(xda.x.values)\n",
    "rows, cols = rowcol(xda.rio.transform(), xs, ys)\n",
    "assets['row'] = rows\n",
    "assets['col'] = cols\n",
    "# we may have coordinates beyond the extent of the DataArray...\n",
    "local_assets = assets[(assets.row >= 0) & (assets.col >= 0)].copy()\n",
    "display(local_assets)\n",
    "    \n",
    "# rio accessors...\n",
    "# isel_window(window: Window, pad: bool = False) → Dataset | DataArray[source]\n",
    "# slice_xy(minx: float, miny: float, maxx: float, maxy: float) → Dataset | DataArray[\n",
    "# xdsc = xds.rio.clip_box, also specifying another CRS\n",
    "\n",
    "# rows, cols should be same shape and order as df...\n",
    "#print(local_assets.row)\n",
    "#print(local_assets.col)\n",
    "\n",
    "def bar(r): # Optional[xarray.DataArray]\n",
    "    da = xda.isel(x=slice(r.col-offset-1, r.col+offset), y=slice(r.row-offset-1, r.row+offset))\n",
    "    if da.size > 0:\n",
    "        return da\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def myfunc(row, col, xdarray, size):\n",
    "    s1 = slice(col-size-1, col+size)\n",
    "    s2 = slice(row-size-1, row+size)\n",
    "    foo = xdarray.isel(x=s1, y=s2)\n",
    "    bar = np.empty([0,]) if foo.size == 0 else foo.data\n",
    "    unique, counts = np.unique(bar, return_counts=True)\n",
    "    years = unique + 2000\n",
    "    result = dict(zip(years, counts))\n",
    "    return result\n",
    "\n",
    "#vfunc = np.vectorize(myfunc)\n",
    "\n",
    "print(f'-> {myfunc(1000, 1000, xda, offset)}')\n",
    "print(f'-> {type(myfunc(1000, 1000, xda, offset))}')\n",
    "\n",
    "#display(local_assets)\n",
    "\n",
    "np_row = local_assets.row.to_numpy()\n",
    "np_col = local_assets.col.to_numpy()\n",
    "\n",
    "print(type(np_row))\n",
    "print(type(np_col))\n",
    "print(np_row.shape)\n",
    "print(np_col.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#my_lambda = lambda r: xda.isel(x=slice(r[12]-offset-1, r[12]+offset), y=slice(r[11]-offset-1, r[11]+offset))\n",
    "# important to specify 'otypes' to avoid 'only size-1 arrays can be converted to Python scalars'\n",
    "# vectorize is just a for loop really so mostly syntactic sugar...\n",
    "# excluded needs both positional and keyword members to be flexible... \n",
    "#otypes=[dict], \n",
    "#, excluded=['xda', 'offset']\n",
    "#, otypes=[dict]\n",
    "#del my_func\n",
    "my_func = np.vectorize(myfunc, excluded=['xdarray','size'], cache=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Nota bene: np.vectorize is consistently a little quicker than apply... %timeit \n",
    "result = my_func(row=np_row, col=np_col, xdarray=xda, size=offset)\n",
    "#%timeit local_assets.apply(lambda r: myfunc(r.row,r.col,xda,offset), axis=1)\n",
    "\n",
    "#display(result)\n",
    "print(result.shape)\n",
    "print(type(result.dtype))\n",
    "\n",
    "poo = pd.Series(result)\n",
    "display(poo[poo.notna()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "local_assets['region'] = pd.Series(result, index=local_assets.index)\n",
    "columns = local_assets.columns.drop('region')\n",
    "print(columns)\n",
    "# expand to columns i.e. to wide format... indexed by uid_gem\n",
    "#display(local_assets[local_assets.index == 'L800190'])\n",
    "#display(local_assets[local_assets.region.notna()])\n",
    "#display(local_assets.tail())\n",
    "#bar = local_assets['region'].apply(pd.Series)\n",
    "#display(bar.tail())\n",
    "local_assets_lossyears = pd.concat([local_assets['region'].apply(pd.Series)], axis=1)\n",
    "# remove nodata before we shift to long format\n",
    "# TODO: where does the colum 0 come from?\n",
    "#local_assets.drop(['region'], inplace=True, axis=1)\n",
    "display(local_assets_lossyears.tail())\n",
    "#local_assets_lossyears.drop([2000, 0], inplace=True, axis=1)\n",
    "local_assets_lossyears.shape, local_assets_lossyears.columns\n",
    "#local_assets_lossyears[local_assets_lossyears[2021].notna()].head(30)\n",
    "#local_assets_lossyears[local_assets_lossyears.index == 'L800190']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the id variables need to uniquely identify each row... \n",
    "# TODO: it does not like region as a dict\n",
    "#foo = pd.wide_to_long(local_assets, stubnames=range(2001, 2023), i=columns, j='lossyear').reset_index()\n",
    "# value_vars=range(2001, 2023) # takes all except id_vars when not given...\n",
    "#display(columns)\n",
    "#display(local_assets.columns)\n",
    "years = local_assets_lossyears.columns\n",
    "display(years)\n",
    "display(local_assets_lossyears)\n",
    "foo = pd.melt(local_assets_lossyears, value_vars=years, var_name='lossyear', value_name='count', ignore_index=False)\n",
    "display(foo.tail())\n",
    "#display(local_assets[local_assets.index == 'L800190'])\n",
    "#display(foo[foo.index == 'L800190'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = foo.groupby(['uid_gem', 'lossyear']).first()\n",
    "bar = bar.reindex(index)\n",
    "bar.ffill(inplace=True)\n",
    "#bar.loc['L800190', ]\n",
    "bar.reset_index(inplace=True)\n",
    "#display(bar[bar.uid_gem == 'L800190'])\n",
    "\n",
    "# pivot on uid_gem and \n",
    "far = bar.pivot(index='uid_gem', columns='lossyear', values='count')\n",
    "display(far.columns)\n",
    "display(local_assets.columns)\n",
    "# combine far with local_assets based on index...\n",
    "local_assets_with_lossyears = pd.merge(local_assets, far, validate='one_to_one', left_on='uid_gem', right_on='uid_gem')\n",
    "\n",
    "display(local_assets_with_lossyears)\n",
    "\n",
    "local_assets_with_lossyears.to_csv('data/geotiff-sample.csv')\n",
    "\n",
    "# Index contains duplicate entries, cannot reshape\n",
    "#foo.pivot(index='uid_gem', columns='start_year_first')\n",
    "\n",
    "\n",
    "#len(uid_gem), len(lossyears)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
